Google launched GeminiAI, the next generation artificial intelligence model, on December 13th.It was said that the product would be more focused on API integrations.I was curious and wanted to use it.It has a very simple use, with a good imagination, it can be very useful in our projects.

I tried 2 api in this example.

1 =>I tried Text-only input using Gemini pro.

2 =>I tried Text-and-image input using Gemini pro vision.


First I got such a response by sending only a text prompt.
![Screenshot 2023-12-16 183951](https://github.com/omererkenn/GeminiAI/assets/42861290/cde7577a-2975-44b1-9f8c-87a7792ac3ea)

Secondly I gave both text and an image and asked it to interpret it.
![photo-1621173744872-ce68058f41ee](https://github.com/omererkenn/GeminiAI/assets/42861290/1128198a-7c32-47b0-97e6-e3519650bc21)

![Screenshot 2023-12-16 193935](https://github.com/omererkenn/GeminiAI/assets/42861290/27c56d2e-31f8-4774-9f9c-8d85393a0c19)

![Screenshot 2023-12-16 194009](https://github.com/omererkenn/GeminiAI/assets/42861290/b46a896c-8930-41c7-afb3-df01f213c512)

Of course our goal should never be just to use it but to understand how it works and how it interprets :)




